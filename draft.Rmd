---
header-includes:
   - \usepackage{ulem}
   - \usepackage{float}
   - \usepackage{algorithm}
   - \usepackage{algorithmic}
output:
  pdf_document
fontsize: 10pt 
editor_options: 
  chunk_output_type: console
bibliography: references.bib  
---

```{r rmarkdown-setup, echo = FALSE}
knitr::opts_chunk$set(echo = FALSE)
knitr::opts_chunk$set(message = FALSE)
knitr::opts_chunk$set(warning = FALSE)
knitr::opts_chunk$set(dev = "cairo_pdf")
knitr::opts_chunk$set(fig.width = 6)
knitr::opts_chunk$set(fig.height = 4)

options(knitr.kable.NA = "")
options(scipen = 999)

```

```{r r-setup}
library(tidyverse)
library(haven) # reading Stata data
library(MASS) # M-estimation
library(Rfit) # rank-based regression
library(patchwork)
library(broom)
library(sandwich)
library(lmtest)
library(NSM3)

```

```{r load-data}
seed011204 = read_stata("dataverse_files/seedanalysis_011204.dta")

seed080404 = read_stata("dataverse_files/seedanalysis_080404.dta")

combined = read_stata("dataverse_files/seedanalysis_011204_080404.dta")

six_months = filter(seed011204, !is.na(treatment))


```

```{r data-cleaning}
# this cleaning is based on Stata scripts from the original Authors' code

combined = combined  %>%
  # turn dollars into hundreds of dollars
  mutate(
    totbal = totbal / 100,
    newtotbal = newtotbal / 100
  ) %>%
  # fix population variable
  mutate(pop = as.numeric(str_replace(pop, ",", ""))) %>%
  # create bank penetration variable%>%
  mutate(brgy_penetration = no_clients / pop)

combined = combined %>%
  # calculate the mean and sd for each bank
  # the Stata code is a little cryptic
  group_by(brgy_penetration) %>%
  mutate(sd_totbal = sd(totbal),
         mean_totbal = mean(totbal)) %>%
  ungroup()

combined = combined %>%
  # create control dummy
  mutate(control = as.numeric(group == "C")) %>%
  # create distance to bank variable
  mutate(dist_GB = 
           case_when(
             butuan == 1 ~ dbutuan,
             ampayon == 1 ~ dampayon
           )
  )

# create a set with the 1777 observations that are in the SEED, 
# marketing treatment, or control group
treated = combined %>%
  filter(!is.na(treatment))

```

# Commitment Savings Devices

## 1. Introduction

## 2. Summary of Data for Analysis

```{r}
seed_accounts = treated %>% filter(treatment == 1)
nonseed = treated %>% filter(treatment == 0)
hist(seed_accounts$balchange,
     main="Histogram of balance changes for SEED accounts",
     xlab="Balance Change")

filtered_seeds = seed_accounts %>% filter(balchange <=10000)
hist(filtered_seeds$balchange,
     main="Outliers removed balance changes for SEED accounts",
     xlab="Balance Change")

print("Summary statistics for Seed account balance changes")
summary(seed_accounts$balchange)


filtered_nonseeds = nonseed %>% filter(balchange<10000)
hist(nonseed$balchange)
hist(filtered_nonseeds$balchange)

```

## 3. Paired Comparisons

### 3.1 Methods

We will use a one sided Wilcoxon Signed-Rank Test at a significance of $\alpha=0.05$ to test if the the savings of customers with SEED accounts increased.

We will be testing the following hypothesis where $\theta_d$ is the mean of the differences in savings for customers with SEED accounts from before and after the trial

$H_0: \theta_d = 0$

$H_a: \theta_d >0$

We will be used a Signed-Rank test given the significant outliers in the data.

The Wilcoxon Signed-Rank Test statistic is done by ranking the absolute values of the paired differences. The ranks are then signed positive or negative based on whether or not the corresponding differences are positive or negative. The test statistic is the sum of the positive ranks. As we have a large number of samples $(n=842)$ the test statistic takes on an approximately normal distribution with 
$E(SR_+) = \frac{n(n+1)}{4} = `r (842 * (842 + 1)) / 4`$ and 
$\text{var}(SR_+) = \frac{n(n+1)(2n+1)}{24}=`r (842 * (842 + 1) * (2 * 842 + 1) / 24)`$. [@Higgins]


### 3.2 Results

```{r wilcox paired test}
wilcox.test(seed_accounts$totbal, seed_accounts$newtotbal,alternative = "greater", paired=TRUE)
```


### 3.3 Discussion of Results

As the p-value is significantly less than our $\alpha$ of $0.05$ we reject the null hypothesis in favor of the alternate hypothesis. We conclude that customers who had SEED accounts saw an increase in savings over the duration of the trial. It is worth noting that we have not yet shown that the SEED accounts are more effective savings accounts than other methods, just that customers were able to save with them.


## 4. Two-sample Test and K-Sample Test

### 4.1 Methods

We know very little about the difference in the underlying distributions of the SEED account savings and the non SEED account savings. We can reasonably assuming independence from each other and continuity of both distributions, but not much else. However, the closest test that matches those assumptions is the Fligner-Policello Test.

The Fligner-Policello Test tests for a difference in population median, but it requires both populations to be symmetric. We feel comfortable violating this assumption here for two reasons. One is that once the comparably small number of outliers are removed, the distributions start to become symmetric. The second reason is that this is the most permissive test of center available to us. 

We will run this test at a significance level of $\alpha=0.05$ with the following hypothesis.

$H_0: \theta_x = \theta_y$

$H_a: \theta_x < \theta_y$

Where $\theta_x$ represents the true median of the difference in balance changes for the control group and $\theta_y$ represents the true median of the difference in balance changes for SEED accounts.


In addition to testing whether or not the SEED accounts are more effective savings than a control group, we also want to confirm that the SEED accounts are more effective than just the marketing that comes with them. To do this we divide the customers into three groups. A control group, a group that receives marketing but not SEED accounts, and the group with SEED accounts.

We will use the Tukey Permutation HSD Test to conduct a multiple comparison test of these groups. The test statistic will be calculated by taking the maximum absolute value of the Mann-Whitney statistic for each pairwise comparison of the three groups. The p-value will be calculated with a re-sampling approach. We will shuffle the data between groups and recalculate the test statistic 10,000 times. The estimated p-value will be the percentage of test statistics greater than or equal to the observed.

We will conduct this test at a significance level of $\alpha=0.05$ with the following hypothesis.

$H_0: \theta_x = \theta_y = \theta_z$

$H_a$ 

To control for type one error we will use Bonferroni's adjustment for the paired test. Giving an adjusted alpha of $\alpha' = \frac{2\alpha}{k(k-1)} = `r 2 * 0.05 / (3 * (3 - 1))`$[@Higgins]

Where $\theta_x, \theta_y, \theta_z$ are the medians of the distributions of the savings in the control group, the marketing group, and the SEED accounts respectively.



### 4.2 Results

```{r 2-sample}
x = list(nonseed$balchange, seed_accounts$balchange)
pFligPoli(x, method="Monte Carlo")
```


```{r Tukey HSD setup}
# Helper functions
comp_sum = function(val, t1){
# Helper function for Mann-Whitney stat
  full = sum(t1 < val)
  partial = 0.5 * sum(t1 == val)
  return(full+partial)
}

mw_stat = function(t1, t2){
  #Mann-Whitney statistic for two treatments
  comp_sums = mapply(comp_sum, t2, MoreArgs = list(t1=t1))
  return(sum(comp_sums))
}

general_stat_perm= function(full_data, n_s, stat_func){
  # stat_func should take in a list of 
  dataset = list()
  k = length(n_s)
  start=1
  end=0
  for (i in 1:k){
    end = end + n_s[i]
    dataset[[i]] = full_data[start:end]
    start = end + 1
  }
  return(stat_func(dataset))
}


calculate_critical = function(stat_dist, alpha){
  # stat_dist is sorted
  R = length(stat_dist)
  init_crit = stat_dist[R*alpha]
  if(sum(sample_q >= init_crit)/R == alpha){
    return(init_crit)
  }
  index = sum(sample_q > init_crit)
  return(sample_q[index])
}

```


```{r Tukey HSD}

seed_balchange = seed_accounts$balchange
marketing_balchange = (treated %>% filter(marketing==1))$balchange
control_balchange = (treated %>% filter(control==1, marketing==0))$balchange

# Permutation Tukey HSD test
q_star = function(dataset){
  # Permutation HSD pg 97
  # Use the Mann-Whitney for T
  k = length(dataset)
  max_t = 0
  for (i in 1:(k-1)) {
    for(j in (i+1):k){
      t = abs(mw_stat(dataset[[i]], dataset[[j]]))
      if (t > max_t){
        max_t = t
      }
    }
  }
  return(max_t)
}

treat_list = list(
  control=control_balchange,
  marketing=marketing_balchange,
  seed=seed_balchange
)

k = length(treat_list)
n_s = mapply(length, treat_list)
N = sum(n_s)
full_data = unlist(treat_list)

R = 10000
permutations = matrix(NA, ncol = N, nrow=R)
for (i in 1:R){
  permutations[i,] = sample(full_data)
}
sample_q = apply(permutations, 1, general_stat_perm, n_s, q_star)
sample_q = sort(sample_q, decreasing = TRUE)

alpha = 0.05
adjusted_alpha = 2*alpha/ (k*(k-1))
print(sprintf("Alpha of %s leads to an adjusted alpha of %s", alpha, adjusted_alpha))


crit_alpha = calculate_critical(sample_q, alpha)
crit_adj = calculate_critical(sample_q, adjusted_alpha)
crit_message = sprintf("critical values of significance levels %s and %s are %s and %s respectively", alpha, adjusted_alpha, crit_alpha, crit_adj)
print(crit_message)

q_obs = q_star(treat_list)
obs_message = sprintf("The observed value of Q* is: %s", q_obs)
print(obs_message)

counts = sum(sample_q>= q_obs)
p_val = counts/R
p_message = sprintf("With a p-value of %s", p_val)
print(p_message)

```


```{r}
m = matrix(NA, k, k, 
           dimnames = list(
             names(treat_list),
             names(treat_list)
            )
          )

for (row in names(treat_list)){
  for(col in names(treat_list)){
    m[row,col] = mw_stat(treat_list[[row]], treat_list[[col]])
  }
}
print("pairwise statistics greater than or equal to the adjusted alpha critical value")
print(m >= crit_adj)
```



### 4.3 Discussion of Results

A p-value of 0.0001 for the Fligner-Policello Test means that we reject the null hypothesis in favor of the alternate. We conclude that the median savings for SEED accounts is higher an for non-SEED accounts.


A p-value of 0 for the Tukey HSD permutation test leads us to reject the null hypothesis in favor of the alternative. We conclude that there is a difference in savings between at least two of the groups. 

The matrix shows that the SEED accounts had better savings than the control group and the marketing groups. No other differences were significant. This allows us to conclude that the SEED accounts had better savings than the other two groups.

## 5. Robust Regression

[@Ashraf2006] estimate regression models with change in savings account balance as the dependent variable and the different treatments and controls as independent variables. This is to estimate the intent-to-treat effect (ITT) of the commitment savings account--that is the effect on account balances of being offered the commitment savings account versus not being offered the account or being offered the marketing treatment instead. 

The dependent variable, change in savings account balance, is highly right-skewed after six months and twelve months. Accordingly, the dependent variable is not approximately normally distributed and the error term of their estimated models is not approximately normally distributed.

```{r}
#
# Create a plot to show the skew of balchange
#
skewa = six_months %>%
  ggplot(aes(balchange)) +
  geom_density() +
  scale_x_continuous(labels = scales::comma) +
  scale_y_continuous(limits = c(0, 0.004)) +
  labs(title = "The Dependent Variables Are Highly Right Skewed",
       subtitle = "Six Month Change in Balance",
       x = "Change in balance (Philippine Peso)",       
       y = NULL) +
  theme_minimal()

skewb = treated %>%
  ggplot(aes(balchange)) +
  geom_density() +
  scale_x_continuous(labels = scales::comma) +
  scale_y_continuous(limits = c(0, 0.004)) +
  labs(title = "",
       subtitle = "Twelve Month Change in Balance",
       x = "Change in balance (Philippine Peso)",
       y = NULL) +  
  theme_minimal()

skewa + skewb

rm(skewa, skewb)

```

The SEED treatment, the marketing control, and the full control all have outliers. Though the SEED treatment's outliers are distinct for the change in twelve month balance. 

```{r}
#
# Create a plot to show the skew of balchange by group
#
skewa = six_months %>%
  ggplot(aes(balchange, y = group, color = group)) +
  geom_point(alpha = 0.2) +
  scale_x_continuous(labels = scales::comma) +
  labs(title = "The Dependent Variables Are Highly Right Skewed",
       subtitle = "Six Month Change in Balance",
       x = "Change in balance (Philippine Peso)",       
       y = NULL) +
  theme_minimal() +
  guides(color = FALSE)

skewb = treated %>%
  ggplot(aes(balchange, y = group, color = group)) +
  geom_point(alpha = 0.2) +
  scale_x_continuous(labels = scales::comma) +
  labs(title = "",
       subtitle = "Twelve Month Change in Balance",
       x = "Change in balance (Philippine Peso)",
       y = NULL) +  
  theme_minimal() +
  guides(color = FALSE)

skewa + skewb

rm(skewa, skewb)

# measure of outliers from 611?

```

[@Ashraf2006] found only modest evidence for a statistically significant intent-to-treat (ITT) effect for the commitment savings accounts using ordinary least squares regression (OLS). Furthermore, they found that the differential effect of being offered the commitment savings product beyond being offered only a marketing treatment was indistinguishable from zero. 

The authors state: 

> The statistical insignificance masks the heterogeneity in the impact of the commitment treatment relative to the marketing treatment throughout the distribution of the change in balance variable. Using measures that minimize the influence of outliers, e.g., the probability of a savings increase and the quantile regressions below, we find a significant commitment-treatment effect relative to the marketing treatment.

To deal with outliers, the authors constructed two binary outcome variables: 
\begin{itemize}
\item 1 if the savings is positive and 0 otherwise. 
\item 1 if the savings increases by more than 20 percent and 0 otherwise. 
\end{itemize}

The authors then estimate probit models on the twelve month data and find statistically significant treatment effects. 

We first explore their constructed variables and then we offer an alternative approach. A closer look at the data show that many balances decreased or remained the same and only a fraction of balances increased after twelve months.

```{r}
#
# Count the types of change in balchange
# 
treated =  treated %>%
  mutate(change =
           case_when(
             balchange > 0 ~ "Increase",
             balchange == 0 ~ "No Change",
             balchange < 0 ~ "Decrease"
           )
  ) %>%
  mutate(change = factor(change, levels = c("Decrease", "No Change", "Increase")))

count(treated, change) %>%
  pivot_wider(names_from = change,
              values_from = n) %>%
  knitr::kable(caption = "Change in Balance After Twelve Months")

```

Importantly, inside the treatment group, more balances decreased than increased in the 12 month window. 

```{r}
count(treated, group, change) %>%
  pivot_wider(names_from = change,
              values_from = n) %>%
  knitr::kable(caption = "Change in Balance After Twelve Months by Treatment Group")

```

The story is even more dramatic for the 20 percent increase outcome variable. 

```{r}
count(treated, frac_change_20) %>%
  pivot_wider(names_from = frac_change_20,
              values_from = n) %>%
  rename(`20%+ Increase` = `1`,
         `<20% Increase` = `0`) %>%
  knitr::kable(caption = "20+% Change in Balance After Twelve Months")

count(treated, group, frac_change_20) %>%
  pivot_wider(names_from = frac_change_20,
              values_from = n) %>%  
  rename(`20%+ Increase` = `1`,
         `<20% Increase` = `0`) %>%  
  knitr::kable(caption = "20+% Change in Balance After Twelve Months")

```

### 5.1 Methods

We offer an alternative approach to dealing with outliers from the nonparametric statistical literature. 

Ordinary least squares regression estimates coefficients, $\vec{\hat{\beta}}$, that minimize the sum of squared residuals 

$$\min_{\vec{\hat{\beta}}} \sum_{i = 1}^N (Y_i - \hat{Y_i})^2$$

The square in this optimization gives extra weight to outliers. In this case, all of the outliers are positive and the squared term will result in an estimated intercept and estimated coefficients that are further from zero in the positive direction. 

Regression with M-estimation estimates coefficients, $\vec{\hat{\beta}}$, that minimize standardized residuals where outliers receive less weight

todo(aaron): citation

$$\min_{\vec{\hat{\beta}}} \sum_{i = 1}^N \rho\left(\frac{Y_i - \hat{Y_i}}{\hat{\sigma}_i}\right)$$

Where $\rho(x)$ is a symmetric function with a unique minimum at $x = 0$ and $\hat{\sigma}$ is an estimate of the standard deviation of the residuals. We use Tukey's bisquare function for $\rho$ such that 

$$\rho(x) = \begin{cases}
\left(\frac{x}{c}\right)^6  - 3\left(\frac{x}{c}\right)^4 + 3\left(\frac{x}{c}\right)^2,  &  |x| \leq c\\
1, & |x| > c
\end{cases}$$

with $c = 4.685$. 

Robust and rank-based regression addresses the issues of OLS outlined above by estimating coefficients, $\vec{\hat{\beta}}$, that minimize the sum of errors weighted by rank scores. 

The Jaeckel-Hettmansperger-McKean (JHM) estimates of the coefficients $\beta_1, \beta_2, ..., \beta_k$ minimizes

$$D_j(\mathbf{Y} - \mathbf{X}\vec{\beta}) = \frac{\sqrt{12}}{(n + 1)}\sum_{i = 1}^n \left[R_i(\vec{\beta}) - \frac{n + 1}{2})\right](Y_i - \mathbf{x'}_i\vec{\beta})$$

Like [@Ashraf2006], we estimate the intent-to-treat (ITT) effect with the change in balance as the dependent variable and the different treatments as the independent variables. Only we use M-Estimation and Robust and rank-based regression. 

### 5.2 Results

We begin by recreating half of Table VI from [@Ashraf2006]. All models are estimated using ordinary least squares regression and the standard errors are HC1 heteroskedasticity-robust standard errors [@MacKinnon1985].

```{r results = "asis"}
#
# OLS model
#
six_months = filter(seed011204, !is.na(treatment))

# column 1
lm1 = lm(balchange ~ treatment + marketing, data = six_months) 
se1 = lm1 %>% coeftest(vcov = vcovHC(., type="HC1"))

# column 2
lm2 = lm(balchange ~ treatment, 
         data = filter(six_months, group %in% c("M", "T"))) 
se2 = lm2 %>% coeftest(vcov = vcovHC(., type="HC1"))

# column 3
lm3 = lm(balchange ~ treatment + marketing, data = treated) 
se3 = lm3 %>% coeftest(vcov = vcovHC(., type="HC1"))

# column 4
lm4 = lm(balchange ~ treatment, 
         data = filter(treated, group %in% c("M", "T"))) 
se4 = lm4 %>% coeftest(vcov = vcovHC(., type="HC1"))

stargazer::stargazer(lm1, lm2, lm3, lm4,
                     se = list(se1[, 2], se2[, 2], se3[, 2], se4[, 2]),
                     header = FALSE,
                     column.separate = c(2, 2),
                     column.labels = c("6 months", "12 months"), 
                     omit.stat = c("adj.rsq", "rsq", "f", "ser"),
                     title = "OLS Model")

```

We estimate identical specifications to [@Ashraf2006] using M-estimation. Column (1) shows the change in balance after six months including all observations. The coefficients estimate the additional savings of the corresponding treatment over the control group. Column (2) shows the change in balance after six months using only the commitment savings group and the marketing group. Column (3) is similar to column (1), only it uses the twelve month change in balance. Likewise, column (4) is similar to column (2), only it uses the twelve month change in balance.

```{r results = "asis"}
#
# M-Estimation model
#

# column 1
m_model1 = rlm(balchange ~ treatment + marketing, method = "M", psi = psi.bisquare, data = six_months)

# column 2
m_model2 = rlm(balchange ~ treatment, method = "M", psi = psi.bisquare, 
               data = filter(six_months, group %in% c("M", "T")))

# column 3
m_model3 = rlm(balchange ~ treatment + marketing, method = "M", psi = psi.bisquare, data = treated)

# column 4
m_model4 = rlm(balchange ~ treatment, method = "M", psi = psi.bisquare, 
               data = filter(treated, group %in% c("M", "T")))

stargazer::stargazer(m_model1, m_model2, m_model3, m_model4,
                     header = FALSE,
                     column.separate = c(2, 2),
                     column.labels = c("6 months", "12 months"), 
                     omit.stat = "ser",
                     title = "M-Estimation Model")

```

We estimate identical specifications to [@Ashraf2006] using robust and rank-based regressions. Column (1) shows the change in balance after six months including all observations. The coefficients estimate the additional savings of the corresponding treatment over the control group. Column (2) shows the change in balance after six months using only the commitment savings group and the marketing group. Column (3) is similar to column (1), only it uses the twelve month change in balance. Likewise, column (4) is similar to column (2), only it uses the twelve month change in balance.

```{r results = "asis"}
#
# Robust and rank-based regression
#

# column 1
rank_model1 = rfit(balchange ~ treatment + marketing, data = six_months)

# column 2
rank_model2 = rfit(balchange ~ treatment, 
                   data = filter(six_months, group %in% c("M", "T")))

# column 3
rank_model3 = rfit(balchange ~ treatment + marketing, data = treated)

# column 4
rank_model4 = rfit(balchange ~ treatment, 
                   data = filter(treated, group %in% c("M", "T")))


stargazer::stargazer(
  m_model1, m_model2, m_model3, m_model4,
  coef = list(coef(rank_model1), coef(rank_model2), coef(rank_model3), coef(rank_model4)),
  se = list(coef(summary(rank_model1))[, 2],
            coef(summary(rank_model2))[, 2],
            coef(summary(rank_model3))[, 2],
            coef(summary(rank_model4))[, 2]),
  header = FALSE,
  column.separate = c(2, 2),
  column.labels = c("6 months", "12 months"), 
  omit.stat = c("adj.rsq", "rsq", "f", "ser"),
  title = "Rank-based robust regression model"
)

```

### 5.3 Discussion of Results

M-estimation and robust rank-based regression lead to very different results than ordinary least squares. 

The weight of the positive outliers leads to a positive estimated intercept and larger estimated coefficients for the treatments in the OLS model. The other two models, which are more robust to outliers, have negative estimated intercepts and estimated coefficients for the treatments that are much closer to zero. For M-estimation and robust ranked based regression, the estimated intercepts are negative and the coefficients, while positive, are smaller in magnitude than the OLS model. That means the conditional means for the commitment savings group, the marketing control group, and the control group are all negative.

The skewed distribution and outliers lead to dramatically larger standard errors and confidence intervals for the OLS model than the two models that are robust to outliers. Interestingly, this means that more coefficients are statistically significant with M-estimation and robust rank-based regression than with OLS regression even though the effect sizes are much smaller. While the intent-to-treat effect is statistically significantly different than zero, the effect sizes are so small that the practical significance is limited. 

The following data  compares the estimated coefficients and confidence intervals from column (3) for all three model types. 

```{r}
#
# Visualize column (3)
#

lm3 = lm(balchange ~ treatment + marketing, data = treated) %>%
  coeftest(vcov = vcovHC(., type="HC1"))

coefficients = bind_rows(
  tibble(
    model = "OLS Model",
    tidy(lm3)
  ),
  tibble(
    model = "M Model",
    tidy(m_model3)
  ),
  tibble(
    model = "Rank-Based\nModel",
    term = c("(Intercept)", "treatment", "marketing"),
    estimate = rank_model3$coefficients,
    std.error = coef(summary(rank_model3))[, 2]
  )
)

coefficients %>%
  mutate(conf.low = estimate - qnorm(0.025) * std.error,
         conf.high = estimate + qnorm(0.025) * std.error) %>%
  mutate(model = factor(model, levels = c("Rank-Based\nModel", "M Model", "OLS Model"))) %>%
  ggplot(aes(x = estimate, 
             y = model,
             xmin = conf.low,
             xmax = conf.high,
             color = model)) +
  geom_pointrange() +
  geom_vline(xintercept = 0, alpha = 0.5) +
  facet_wrap(~term, scales = "free_x") +
  labs(title = "Model Choice Affects Estimated Coefficients",
       x = "Estimated Beta and 95% Confidence Interval",
       y = NULL) +
  theme_bw() +
  theme(legend.position = "top")

```

The following data visualization compares the estimated coefficients and confidence intervals from column (4) for all three model types. 

```{r}
#
# Visualize column (4)
#

lm4 = lm(balchange ~ treatment, 
         data = filter(treated, group %in% c("M", "T"))) %>%
  coeftest(vcov = vcovHC(., type="HC1"))

coefficients = bind_rows(
  tibble(
    model = "OLS Model",
    tidy(lm4)
  ),
  tibble(
    model = "M Model",
    tidy(m_model4)
  ),
  tibble(
    model = "Rank-Based\nModel",
    term = c("(Intercept)", "treatment"),
    estimate = rank_model4$coefficients,
    std.error = coef(summary(rank_model4))[, 2]
  )
)

coefficients %>%
  mutate(conf.low = estimate - qnorm(0.025) * std.error,
         conf.high = estimate + qnorm(0.025) * std.error) %>%
  mutate(model = factor(model, levels = c("Rank-Based\nModel", "M Model", "OLS Model"))) %>%
  ggplot(aes(x = estimate, 
             y = model,
             xmin = conf.low,
             xmax = conf.high,
             color = model)) +
  geom_pointrange() +
  geom_vline(xintercept = 0, alpha = 0.5) +
  facet_wrap(~term, scales = "free_x") +
  labs(title = "Model Choice Affects Estimated Coefficients",
       x = "Estimated Beta and 95% Confidence Interval",
       y = NULL) +
  theme_bw() +
  theme(legend.position = "top")

```

## Conclusion

\newpage

## Appendix

```{r ref.label = knitr::all_labels(), echo = TRUE, eval = FALSE}
```

## References
